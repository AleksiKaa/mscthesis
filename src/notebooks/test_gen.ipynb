{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e6f70b-4524-43c9-bf8d-ffc5e857f792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: module\n",
      "zsh:1: command not found: module\n"
     ]
    }
   ],
   "source": [
    "!module load model-huggingface\n",
    "!module load scicomp-llm-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb1635b5-1774-4850-b0cb-aa1a60383482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    ")  # Add parent directory to path\n",
    "\n",
    "from utils.prompts import (\n",
    "    JUDGE_SYSTEM_PROMPT,\n",
    "    JUDGE_TEMPLATE,\n",
    "    GENERATE_EXERCISES_SYSTEM_PROMPT,\n",
    "    GENERATE_EXERCISES_TEMPLATE_EXPLICIT,\n",
    "    GENERATE_EXERCISES_TEMPLATE_FEWSHOT,\n",
    "    GENERATE_EXERCISES_TEMPLATE_IMPLICIT,\n",
    "    GENERATE_EXERCISES_TEMPLATE_ZEROSHOT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63819a30-71dd-4097-9b8f-955ff90c1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DATA = r\"../../data/complete_dataset.csv\"\n",
    "DEFAULT_MODEL = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "\n",
    "system_prompts = {\n",
    "    \"judge\": JUDGE_SYSTEM_PROMPT,\n",
    "    \"zeroshot\": GENERATE_EXERCISES_SYSTEM_PROMPT,\n",
    "    \"fewshot\": GENERATE_EXERCISES_SYSTEM_PROMPT,\n",
    "    \"explicit\": GENERATE_EXERCISES_SYSTEM_PROMPT,\n",
    "    \"implicit\": GENERATE_EXERCISES_SYSTEM_PROMPT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefac211-9560-4ac8-9849-0c6994fa6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(row, task_type):\n",
    "    _, topic, theme, concept, problem_description, example_solution, *_ = row\n",
    "\n",
    "    match task_type:\n",
    "        case \"judge\":\n",
    "            return (\n",
    "                JUDGE_TEMPLATE.replace(\"$THEME$\", theme)\n",
    "                .replace(\"$TOPIC$\", topic)\n",
    "                .replace(\"$CONCEPT$\", concept)\n",
    "                .replace(\"$TEXT$\", problem_description)\n",
    "                .replace(\"$CODE$\", example_solution)\n",
    "            )\n",
    "        case \"zeroshot\":\n",
    "            return GENERATE_EXERCISES_TEMPLATE_ZEROSHOT\n",
    "        case \"fewshot\":\n",
    "            return GENERATE_EXERCISES_TEMPLATE_FEWSHOT\n",
    "        case \"explicit\":\n",
    "            return GENERATE_EXERCISES_TEMPLATE_EXPLICIT\n",
    "        case \"implicit\":\n",
    "            return GENERATE_EXERCISES_TEMPLATE_IMPLICIT\n",
    "        case _:\n",
    "            raise ValueError(f\"Task type '{_}' not recognised as valid task type!\")\n",
    "\n",
    "\n",
    "def run_model(pipe, data, task_type):\n",
    "    system_prompt = system_prompts.get(task_type, None)\n",
    "\n",
    "    if system_prompt is None:\n",
    "        raise ValueError(f\"Task type '{task_type}' not recognised as valid task type!\")\n",
    "\n",
    "    response = pipe(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": data[\"prompt\"]},\n",
    "        ],\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=500,\n",
    "    )\n",
    "\n",
    "    result = response[0][\"generated_text\"]\n",
    "    result_dict = json.loads(result)\n",
    "\n",
    "    for k, v in result_dict.items():\n",
    "        data[k] = v\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03a9d92-d491-4d47-ac27-0ad881d00537",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"judge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b1f6344-aace-4acd-a6b3-2a723ba0895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 13:17:48.061828: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ce38a21f874503accac6a637fe8196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd582f3a56ee489bac212591a5aecbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b683f3d81b41cab76e086dce2b98ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e769041024ac42ecb7432c6288d63e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b1ba5751b9469c9fa4c2fd43259422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7348474cac2e4bcc95c13bf5bc2d787e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/1.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e100afcde774948943589a578b95977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033af495f79e46f8a69b5606ec48f034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a9c1eb5ff74b1fa4380206895354f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"model\": DEFAULT_MODEL,\n",
    "    \"device_map\": 0,  # Force GPU\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.3,\n",
    "}\n",
    "\n",
    "pipeline = transformers.pipeline(\"text-generation\", **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a27dea-69bd-46e8-b38f-77f94b198b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv(DEFAULT_DATA, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfde45-584c-4ab3-8eee-117273fe1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"prompt\"] = eval_df.apply(lambda row: make_prompt(row, task), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafee9a3-98cc-4fbe-9d6c-78ecefe92d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = eval_df.apply(lambda row: run_model(pipeline, row, task), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python generic (scicomp-python-env/2025.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
