%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                            %%
%% thesistemplate_short.tex version 4.10 (2025/06/30)                         %%
%% The LaTeX template file to be used with the aaltothesis.sty (version 4.10) %%
%% style file.                                                                %%
%% This package requires pdfx.sty v. 1.5.84 (2017/05/18) or newer.            %%
%%                                                                            %%
%% This is licensed under the terms of the MIT license below.                 %%
%%                                                                            %%
%% Written by Luis R.J. Costa.                                                %%
%% Currently developed at Teacher services, Learning Services of Aalto        %%
%% University by Luis R.J. Costa since May 2019.                              %%
%%                                                                            %%
%% Copyright 2017-2025 aaltothesis.cls by Luis R.J. Costa,                    %%
%% luis.costa@aalto.fi.                                                       %%
%% Copyright 2017-2018 Swedish translations in aaltothesis.cls by Elisabeth   %%
%% Nyberg and Henrik Wallén henrik.wallen@aalto.fi.                           %%
%% Copyright 2017-2018 Finnish documentation in the template opinnatepohja.tex%%
%% by Perttu Puska, perttu.puska@aalto.fi, and Luis R.J. Costa.               %%
%% Finnish documentation in the template opinnatepohja.tex translated from    %%
%% the English template documentation.                                        %%
%% Copyright 2025 English template thesistemplate.tex by Luis R.J. Costa,     %%
%% Maurice Forget, Henrik Wallén.                                             %%
%% Copyright 2018-2025 Swedish template kandidatarbetsbotten.tex by Henrik    %%
%% Wallen.                                                                    %%
%%                                                                            %%
%% Permission is hereby granted, free of charge, to any person obtaining a    %%
%% copy of this software and associated documentation files (the "Software"), %%
%% to deal in the Software without restriction, including without limitation  %%
%% the rights to use, copy, modify, merge, publish, distribute, sublicense,   %%
%% and/or sell copies of the Software, and to permit persons to whom the      %%
%% Software is furnished to do so, subject to the following conditions:       %%
%% The above copyright notice and this permission notice shall be included in %%
%% all copies or substantial portions of the Software.                        %%
%% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR %%
%% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,   %%
%% FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL    %%
%% THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER %%
%% LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING    %%
%% FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER        %%
%% DEALINGS IN THE SOFTWARE.                                                  %%
%%                                                                            %%
%%                                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                            %%
%% A concise template in English. For more detailed instructions in the use   %%
%% of this template and LaTeX-specific example see the English and Finnish    %%
%% templates thesistemplate.tex and opinnaytepohja.tex.                       %%
%%                                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                            %%
%%                                                                            %%
%% An example for writting your thesis using LaTeX                            %%
%% Original version and development work by Luis Costa, changes to the text   %% 
%% in the Finnish template by Perttu Puska.                                   %%
%% Support for Swedish added 15092014                                         %%
%% PDF/A-b support added on 15092017                                          %%
%% PDF/A-2 support added on 24042018                                          %%
%% Layout design and typesettin changed 15072021                              %%
%%                                                                            %%
%% This example consists of the files                                         %%
%%       thesistemplate.tex (version 4.10) (for text in English)              %%
%%       opinnaytepohja.tex (version 4.10) (for text in Finnish)              %%
%%       kandidatarbetsbotten.tex (version 1.20) (for text in Swedish)        %%
%%       thesistemplate_short.tex (version 4.10) (abridged for text in        %%
%%                                                English)                    %%
%%       aaltothesis.cls                                                      %%
%%       linediagram.pdf (graphics file)                                      %%
%%       curves.pdf      (graphics file)                                      %%
%%       ledspole.jpg    (graphics file)                                      %%
%%                                                                            %%
%%                                                                            %%
%% Typeset in Linux with                                                      %%
%% pdflatex: (recommended method)                                             %%
%%             $ pdflatex thesistemplate                                      %%
%%             $ pdflatex thesistemplate                                      %%
%%                                                                            %%
%%   The result is the file thesistemplate.pdf that is PDF/A compliant, if    %%
%%   you have chosen the proper \documenclass options (see comments below)    %%
%%   and your included graphics files have no problems.                       %%
%%                                                                            %%
%%                                                                            %%
%% Explanatory comments in this example begin with the characters %%, and     %%
%% changes that the user can make with the character %                        %%
%%                                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%
%% USE one of the following three \documentclass set-ups:
%% * the first when using pdflatex to directly typeset your document in the
%%   chosen pdf/a format for online publishing (centred page layout),
%% * the second for one-sided printing your thesis with the layout (wide left 
%%   margin), or
%% * the third for two-sided printing.
%%
\documentclass[english, 12pt, a4paper, sci, utf8, a-2b, online]{../definitions/aaltothesis}
%\documentclass[english, 12pt, a4paper, elec, utf8, a-2b, print]{aaltothesis}
%\documentclass[english, 12pt, a4paper, elec, utf8, a-2b, print, twoside]{aaltothesis}

%% Use the following options in the \documentclass macro above:
%% your school: arts, biz, chem, elec, eng, sci
%% the character encoding scheme used by your editor: utf8, latin1
%% thesis language: english, finnish, swedish
%% make an archiveable PDF/A-1b or PDF/A-2b compliant file: a-1b, a-2b
%%                    (with pdflatex, a normal pdf containing metadata is
%%                     produced without the a-*b option)
%%                    NOTE: when using option a-1b, do not use doclicense
%%                    features to typeset the copyright text. The transparency
%%                    in the image is incompatible with the PDF/A-1 standard.
%% typset for online document or print on paper: online, print
%%        online: typeset in symmetric layout and blue hypertext for online
%%                publishing
%%        print: typeset in a symmetric layout and black hypertext for printing
%%               on paper
%%          two-side printing: twoside (default is one-sided printing)
%%               typeset in a wide margin on the binding side of the page and
%%               black hypertext. Use with print only.
%%

%% FOR USERS OF AMS PACKAGES:
%% * newtxmath used in this template loads amsmath, so
%%   you needn't load it. If you want to use options in amsmath, load it here, 
%%   before \setupthesisfonts below to pass the options to amsmath.
%% * If you want to use amsthm, load it here before \setupthesisfonts to avoid
%%   a clash with newtxmath.
%% * If using amsmath with options and you want to use amsthm, load amsthms
%%   after amsmath, as described in the amsthm documentation.
%% * Don't use amsbsym or amsfonts. The symbols [and macros] there are defined in
%%   newtxmath and so clash if used.
%\usepackage[options]{amsmath}
%\usepackage{amsthm}

%% DO NOT MOVE OR REMOVE \setupthesisfonts
\setupthesisfonts

%%
%% Add here the packges you need
%%
\usepackage{graphicx}


%% For tables that span multiple pages; used to split a paraphrasing example in
%% the appendix. If you don't need it, remove it.
\usepackage{longtable}

%% A package for generating Creative Commons copyright terms. If you don't use
%% the CC copyright terms, remove it, since otherwise undesired information may
%% be added to this document's metadata.
\usepackage[type={CC}, modifier={by-nc-sa}, version={4.0}]{doclicense}
%% Find below three examples for typesetting the CC license notice.

%%%%%%%%%%%%%%%%%%%%%%%%%% FOR THOSE WHO USE BIBLATEX %%%%%%%%%%%%%%%%%%%%%%%%%%
%% Package to use BibLaTeX with some settings. Adjust and add BibLaTeX settings
%% to suit your needs. See the package documentation for available options.
%% The bibliography printing and associated commands are below between the
%% conclusions and the appendix.
%%
\usepackage[
backend=biber,
style=numeric-comp, % citations and references are numerical (Vancouver, IEEE)
sorting=nyt, % references are in alphabetical order sorted in the order name,
             % year, and title.
% sorting=none, % references listed in the order of citation
firstinits=true, % show initial of first name in bibliography
urldate=long % date is expressed as Month dd, yyyy
]{biblatex}
\addbibresource{../references/refs.bib}
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% END BIBLATEX STUFF %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Edit to conform to your degree programme
%% Capitalise the words in the name of the degree programme: it's a name
\degreeprogram{Computer, Communication and Information Sciences}
%%

%% Your major
%%
\major{Computer Science}
%%

%% Choose one of the three below
%%
%\univdegree{BSc}
\univdegree{MSc}
%\univdegree{Lic}
%%

%% Your name (self explanatory...)
%%
\thesisauthor{Aleksi Elias Kääriäinen}
%%

%% Your thesis title and possible subtitle comes here and possibly, again,
%% together with the Finnish or Swedish abstract. Do not hyphenate the title
%% (and subtitle), and avoid writing too long a title. Should LaTeX typeset a
%% long title (and/or subtitle) unsatisfactorily, you might have to force a
%% linebreak using the \\ control characters. In this case...
%% * Remember, the title should not be hyphenated!
%% * A possible 'and' in the title should not be the last word in the line; it
%%   begins the next line.
%% * Specify the title (and/or subtitle) again without the linebreak characters
%%   in the optional argument in box brackets. This is done because the title
%%   is part of the metadata in the pdf/a file, and the metadata cannot contain
%%   linebreaks.
%%
\thesistitle{Hallucination Detection and Prevention in CS Education in AI-generated content}
%\thesistitle[Title of the thesis]{Title of\\ the thesis}
%%
%% Either remove or leave \thesissubtitle{} empty if you don't use it
%%
%\thesissubtitle{A possible subtitle}%
%\thesissubtitle[Subtitle of the thesis]{Subtitle of\\ the thesis}
%\thesissubtitle{}

%%
\place{Espoo}
%%

%% The date for the bachelor's thesis is the day it is presented
%%
\date{\today}
%%

%% Thesis supervisor
%% Note the "\" character in the title after the period and before the space
%% and the following character string.
%% This is because the period is not the end of a sentence after which a
%% slightly longer space follows, but what is desired is a regular interword
%% space.
%%
\supervisor{Prof.\ Juho Leinonen}
%%

%% Advisor(s)---two at the most---of the thesis. Check with your supervisor how
%% many official advisors you can have.
%%
\advisor{Ms Evanfiya Logacheva (MSc)}
%%

%% If you do your thesis work in a company of other institute, give the name of
%% the company or instution here. Otherwise, leave the macro empty, comment it
%% out, or remove it. This will remove this field from the abstract page.
%%
%\collaborativepartner{Company or institute name (if relevant)}%
%%

%% Aaltologo: syntax:
%% \uselogo{?|!|'|aalto?|aalto!|aalto'|<empty>}
%% The logo language is set to be the same as the thesis language.
%%
%\uselogo{?}
%\uselogo{!}
\uselogo{'}
%\uselogo{aalto?}
%\uselogo{aalto!}
%\uselogo{aalto'}
%\uselogo{}
%%

%%%%%%%%%%%%%%%%%%               COPYRIGHT TEXT               %%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Copyright of a work is with the creator/author of the work regardless of
%% whether the copyright mark is explicitly in the work or not. You may, if you
%% wish---we encourage you to do so---publish your work under a Creative
%% Commons license (see creativecommons.org), in which case the license text
%% must be visible in the work. Write here the copyright text you want using the
%% macro \copyrighttext, which writes the text into the metadata of the pdf file
%% as well.
%%
%% Syntax:
%% \copyrigthtext{metadata text}{text visible on the page}
%%
%% CHOOSE ONE OF THE COPYRIGHT NOTICE STYLES BELOW.
%% IF USING THE CC TERMS, CHOOSE THE LICENSE YOU WANT TO USE.
%% The different CC licenses are listed at 
%% https://creativecommons.org/about/cclicenses/.
%% If you use the icons from the doclicense.sty package, add the package above
%% (\usepackage{doclicense}).
%% IMPORTANT NOTE!! Manually write the CC text in the \copyrighttext metadata
%% text field.
%%
%% NOTE: In the macros below, the text written in the metadata must have a
%% \noexpand macro before the \copyright special character. When not in pdf/a
%% mode (i.e. a-1b or a-2b are not specified in \documentclass), two \noexpands
%% are required in the metadata text to correctly render the copyright mark in
%% the pdf metadata. In pdf/a mode one \noexpand suffices.
%%
%% EXAMPLE OF PLAIN COPYRIGHT TEXT
%% The macros \copyright and \year below must be separated by the \ character 
%% (space chacter) from the text that follows. The macros in the argument of the
%% \copyrighttext macro automatically insert the year and the author's name.
%% (Note! \ThesisAuthor is an internal macro of the aaltothesis.cls class file).
%%
%\copyrighttext{Copyright \noexpand\textcopyright\ \number\year\ \ThesisAuthor}
%{Copyright \textcopyright{} \number\year{} \ThesisAuthor}
%%
%% Of course, the same text could have simply been written as
%% \copyrighttext{Copyright \noexpand\copyright\ 2018 Eddie Engineer}
%% {Copyright \copyright{} 2022 Eddie Engineer}
%%
%% EXAMPLES OF CC LICENSE: different ways to display the same license
%% 1. A simple Creative Commons license text with a link to the copyright notice:
%\copyrighttext{\noexpand\textcopyright\ \number\year. This work is 
%	licensed under a CC BY-NC-SA 4.0 license.}{\textcopyright{} 
%	\number\year. This work is licensed under a 
%	\href{https://creativecommons.org/licenses/by-nc-nd/4.0/}{CC BY-NC-SA 4.0} 
%	license.}
%
%% To get the URL of the license of your choice, go to 
%% https://creativecommons.org/about/cclicenses/, click on the chosen license
%% you want to use, and copy-and-paste the URL in the macro \href above.
%%
%% 2. A short Creative Commons license text containing the respective CC icons
%% (requires the package doclicense.sty to be added in the preamble as done
%% above) and a link to the corresponding Creative Commons license webpage (see
%% the doclicense package documentation for other license icons):
%\copyrighttext{\noexpand\textcopyright\ \number\year. This work is licensed
%	under a CC BY-NC-SA 4.0 license.}{
%	\parbox{95mm}{\noindent\textcopyright\ \number\year. \doclicenseText} 
%	\hspace{1em}\parbox{35mm}{\doclicenseImage}
%}
%%
%% 3. An expanded Creative Commons license text containing the respective CC
%% icons text and as generated by the doclicense.sty package (the license is set
%% via package options in \usepackage[options]{doclicense} above; see the
%% doclicense package documentation for other license texts and icons):
\copyrighttext{\noexpand\textcopyright\ \number\year. This work is 
	licensed under a Creative Commons "Attribution-NonCommercial-ShareAlike 4.0 
	International" (BY-NC-SA 4.0) license.}{\noindent\textcopyright\ \number
	\year \ \doclicenseThis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% The English abstract:
%% All the details (name, title, etc.) on the abstract page appear as specified
%% above.
%% Thesis keywords:
%% Note! The keywords are separated using the \spc macro
%%
\keywords{Liiba\spc laaba\spc foo\spc 
bar}
%%

%% The abstract text. This text in one paragraph is included in the metadata of
%% the pdf file as well as the abstract page. To have paragraphs in your
%% abstract rewrite it in the abstarct environment as described below.
%%
\thesisabstract{%
The abstract is a short description of the essential contents of the thesis
usually in one paragraph: what was studied and how and what were the main
findings. For a Finnish thesis, the abstract should be written in both Finnish
and English; for a Swedish thesis, in Swedish and English. The abstracts for
English theses written by Finnish or Swedish speakers should be written in
English and either in Finnish or in Swedish, depending on the student’s language
of basic education. Students educated in languages other than Finnish or Swedish
write the abstract only in English. Students may include a second or third
abstract in their native language, if they wish. 
The abstract text of this thesis is written on the readable abstract page as
well as into the pdf file's metadata via the thesisabstract macro (see the 
comment in the TeX file). Write here the text that goes into the metadata. The 
metadata cannot contain special characters, linebreak or paragraph break 
characters, so these must not be used here. If your abstract does not contain 
special characters and it does not require paragraphs, you may take advantage of
the abstracttext macro (see the comment in the TeX file below). Otherwise, the 
metadata abstract text must be identical to the text on the abstract page.
}

%% You can prevent LaTeX from writing into the xmpdata file (it contains all the 
%% metadata to be written into the pdf file) by setting the writexmpdata switch
%% to 'false'. This allows you to write the metadata in the correct format
%% directly into the file thesistemplate.xmpdata.
%\setboolean{writexmpdatafile}{false}


%% All that is printed on paper starts here
%%
\begin{document}

%% Create the coverpage
%%
\makecoverpage

%% Typeset the copyright text.
%% If you wish, you may leave out the copyright text from the human-readable
%% page of the pdf file. This may seem like a attractive idea for the printed
%% document especially if "Copyright (c) yyyy Eddie Engineer" is the only text
%% on the page. However, the recommendation is to print this copyright text.
%%
\makecopyrightpage

\clearpage
%% Note that when writing your thesis in English, place the English abstract
%% first followed by the possible Finnish or Swedish abstract.

%% Abstract text
%% All the details (name, title, etc.) on the abstract page appear as specified
%% above. Add your abstarct text with paragraphs here to have paragraphs in the
%% visible abstract page. Nonetheless, write the abstarct text without
%% paragraphs in the macro \thesismacro so that it is added to the metadata as
%% well.
%%
\begin{abstractpage}[english]
    \abstracttext{}
\end{abstractpage}

%% The text in the \thesisabstract macro is stored in the macro \abstractext, so
%% you can use the text metadata abstract directly as follows:
%%
%\begin{abstractpage}[english]
%	\abstracttext{}
%\end{abstractpage}

%% Force a new page so that the possible Finnish or Swedish abstract does not
%% begin on the same page
%%

\dothesispagenumbering{}

%% Preface
%%
%% This section is optional. Remove it if you do not want a preface.
\mysection{Preface}
Liirumlaarum

\vspace*{\fill}
Otaniemi, \today \\

\vspace{5mm}
{\hfill Aleksi E.\ Kääriäinen \hspace{1cm}}

%% Force a new page after the preface
%%
\newpage


%% Table of contents. 
%%
\thesistableofcontents


%% Symbols and abbreviations
\mysection{Symbols and abbreviations}

\subsection*{Symbols}

\begin{tabular}{ll}
place & holder \\
\end{tabular}

\subsection*{Operators}

\begin{tabular}{ll}
place & holder \\
\end{tabular}

\subsection*{Abbreviations}

\begin{tabular}{ll}
CS      & Computer Science \\
LM      & Language Model \\
NLP     & Natural Language Processing \\
LLM     & Large Language Model \\
ICL     & In-Context Learning \\
PLM     & Pre-trained Language Model \\
SFT     & Supervised Fine-Tuning \\
RLHF    & Reinforcement Learning from Human Feedback \\
NLG     & Natural Language Generation \\
RAG     & Retrieval-Augmented Generation \\
%ML      & Machine Learning \\
%AI      & Artificial Intelligence \\
\end{tabular}


%% \clearpage is similar to \newpage, but it also flushes the floats (figures
%% and tables).
%%
\cleardoublepage

%% Text body begins. 
%%
\section{Introduction}
\label{sec:intro}

%% Leave page number of the first page empty
%% 
\thispagestyle{empty}

\textbf{TODO: citations in intro! along with text improvements }

The recent advances in Language Models (LMs) have significantly extended the capabilities of computational Natural Language Processing (NLP) and text generation. Modern LMs are commonly transformer-based and pretrained on a Web-scale text corpora. These models are usually called Large Language Models (LLMs). LLMs, such as GPT-4 and Llama 4, have been shown to excel at a number of text-related tasks, including the generation of program code \cite{Minaee2024-fr}.

Computer Science (CS) education and programming skills are usually obtained by completing sets of various exercises. These exercises are typically created by hand by the teaching staff. Distributing the same set of exercises to a large group of students may lead to the students sharing the answers, which hinders learning, or the lack of relevant context in the exercises might not inspire students to complete them. Personalizing and contextualizing the exercises has been shown to increase student's engagement and improve the learning outcome. However, personalizing each exercise is a laborious task and is unfeasible for most CS teachers.

Since the emergence of LLMs, researchers, particularly in the field of CS education, have been interested in the models' ability to generate contextualized text, including computer program code, that is nearly indistinguishable from content written by humans. The use of LLMs in the creation of educational materials have a number of advantages compared to creating each exercise by hand: LLMs decrease the amount of time needed to create each exercise, they allow deep personalization of the exercises and can also be used to create the supporting artifacts in the assignments, including starter code, hints, and example solutions. Time-effectiveness and personalization are not the only important factors in creating educational content, however, it is also crucial to ensure that the materials offered to students are of high quality.

Various aspects of the training data, the training phase, and inference make LLMs prone to hallucinations. A hallucination in the context of LLMs is a model-generated output that is "either
nonsensical or unfaithful to the provided source content". \cite{10.1145/3703155}. Hallucinations decrease the quality of the generated content, and in an educational environment, may make the content unusable \cite{10.1145/3769994.3770036}. Manually checking each output for erroneous content is time-consuming and prone to human-error. For this reason, it would be highly advantageous to mitigate hallucinations produced or to have the ability to detect and correct output containing hallucinations. 

One promising method of preventing hallucinations is in-context learning (ICL). ICL is the practice of introducing incorrect examples for the model as a demonstration and letting the model learn from them \cite{dong-etal-2024-survey}. ICL has shown great promise in reasoning-heavy tasks, such as mathematical reasoning \cite{an2024learningmistakesmakesllm}. Extending ICL to the generation of program code and programming exercises could decrease the amount of human input needed to create programming exercises.

\textbf{TODO: define scope!} This thesis investigates possible methods for detecting, preventing, or reducing hallucinations in educational CS content generated using LLMs. The study provides an empirical comparison of performance between implicit and explicit in-context learning in LLMs used in the generation of CS education content. The main research questions in this thesis are as follows:

\begin{itemize}
    \item \textbf{RQ1: How effective is a state-of-the-art LLM in generating hallucination-free programming exercises?} This includes researching the effect of the prompt used in the generation, optimizing the prompt structures, and analyzing the faithfulness and factuality of the output.
    \item \textbf{RQ2: Can LLMs learn from previously produced erroneous content, producing higher quality content?} The objective of this research question is to find out whether in-context learning can be extended to the generation of CS education material and how much does in-context learning improve the output quality.
    \item \textbf{RQ3: Can CS education materials generated using implicit in-context learning achieve the same level of quality, or outperform explicit in-context learning?} If the answer to the second research question is yes, the next point of interest is to compare the performance of the two different types of ICL.
\end{itemize}

These questions determine the course and content of the study. The thesis is structured as follows:

\begin{itemize}
    \item \textbf{Background:} In this section, existing relevant literature is reviewed and past studies are explained in order to understand the current state of research and bring the readers to a common level of knowledge on the subject. The first topic covered is the Fundamentals of Large Language Models, then Hallucinations in LLMs. After that, a brief explanation on Hallucination Mitigation Methods, and LLMs in CS Education, and finally, existing research in Automatic exercise generation is covered.
    \item \textbf{Research material and methods:} \textbf{TODO: content}
    \item \textbf{Results:} \textbf{TODO: content}
    \item \textbf{Conclusions:} \textbf{TODO: content}
\end{itemize}

%% In a thesis, every section/chapter starts a new page, hence the \clearpage
\clearpage

\section{Background}

This chapter explains the \textbf{TODO: finish paragraph!}

\subsection{Fundamentals of Large Language Models}

Large Language Models belong to the family of Pre-trained Language Models (PLMs). PLMs are task-agnostic, neural-network based, stochastic text prediction functions, trained on very large text corpora. The models operate by outputting the most likely next unit of text given a snippet of text as input. In essence, LLMs are large-scale PLMs, having tens to hundreds of billions of parameters. However, the distinction between the two is necessary, since LLMs have far stronger language understanding and generation abilities than PLMs, and also exhibit capabilities that are not present in PLMs, such as ICL, instruction following, and multi-step reasoning \cite{Minaee2024-fr}.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{latex/images/transformer_architecture.png}
\caption{The Transformer architecture \cite{DBLP:journals/corr/VaswaniSPUJGKP17}}
\label{fig:transformer}
\end{figure}

Most LLMs are based on the Transformer architecture, introduced in \cite{DBLP:journals/corr/VaswaniSPUJGKP17}. The most important innovation in the Transformer model is the application of the attention mechanism, which captures long-term contextual dependencies in the input text, to the parallelizable architecture, depicted in figure \ref{fig:transformer}. This architecture allows for efficiently pre-training very large LMs that have been shown to outperform other existing Neural Language Models, such as Recurrent and Convolutional Language Models \cite{DBLP:journals/corr/VaswaniSPUJGKP17}.

The Transformer model consists of an encoder stack and a decoder stack, pictured on the left and right sides of figure \ref{fig:transformer}, respectively. The encoder maps the input from a sequence of symbols $(x_1, \cdots, x_n)$, to a continuous representation of the symbols $z = (z_1, \cdots, z_n)$. Given $z$, the decoder generates an output sequence $y = (y_1, \cdots, y_m)$ of symbols one symbol at a time. The decoder is auto-regressive, which means that it consumes previously generated symbols $(y_1, \cdots, y_{k-1})$ as an additional input when generating the next $y_k$ \cite{DBLP:journals/corr/VaswaniSPUJGKP17}. Such \textit{Encoder-Decoder models} are best suited for sequence-to-sequence language tasks that are conditioned on input, such as text summarization and language translation tasks \cite{Minaee2024-fr}.

However, many LLMs, most notably the GPT-family and the Llama-family, omit the encoder completely and are strictly \textit{Decoder-Only models} \cite{Minaee2024-fr}. These models function purely as auto-regressive language models, predicting the next token based only on previous tokens. Decoder-Only models have been shown to excel in different text generation tasks, such as answering questions and generating program code \cite{Chen2021EvaluatingLL}.

\subsubsection{Training Stages of LLMs} \label{sec:training}

In order for any neural LM to be able to take text as input, the text first has to be converted to a form that the LM can understand. Tokenization is the practice of breaking down text into smaller chunks, called tokens. A token is the basic unit of operation in LMs. The most basic tokenizers split text on whitespace, but more advanced tokenizers break each individual word into subwords, or even into single characters. Using smaller tokens enables combining multiple tokens to form words, effectively increasing the size of the vocabulary and decreasing the chance of out-of-vocabulary encounters \cite{Minaee2024-fr}.

Neural language models, like the Transformer and LLMs, convert tokens further into an embedding, which is a high-dimensional vector representation of the token. This is usually done in the learnable embedding layer \cite{DBLP:journals/corr/VaswaniSPUJGKP17}, which means that the model optimizes the vector representation of each token, allowing capture and measurement of word similarities and distances. Additionally, positional encoding is included in the embeddings, which allows the model to learn positional dependencies and to carry contextual information spread out in the input sequence.

LLMs acquire their capabilities through a three phase training process:

\begin{enumerate}
    \item \textbf{Pre-training:} During this phase, the LLM undergoes autoregressive prediction of subsequent tokens in text sequences. The self-supervised training on large textual corpora, often covering a significant portion of textual content on the internet, results in the LLM acquiring knowledge of language syntax, world knowledge, and reasoning abilities \cite{10.1145/3703155}. However, during this phase, the model also learns biases, infactualities, and half-truths present in the training data \cite{Kalai2025-fl}.
    
    \item \textbf{Supervised Fine-Tuning:} While pre-training focuses on refining the text completion and language understanding abilities, Supervised Fine-Tuning (SFT) focuses on enchancing the model's task completion ability. During SFT, the model is fed pairs of $(\texttt{instruction, output})$, where \texttt{instruction} (e.g., write an email to person $X$ on the topic $Y$) is the input, instructing the model to complete a specific task, and \texttt{output} is the desired outcome of the task. The objective of using $(\texttt{instruction, output})$ pairs is to constrain the model's outputs to a desired domain of knowledge and align the model with specific response characteristics \cite{zhang2025instructiontuninglargelanguage}. The datasets used in this phase are usually constructed from existing annotated natural language datasets. Examples of such datasets are Flan \cite{longpre2023flancollectiondesigningdata} and P3 (Public Pool of Prompts) \cite{sanh2022multitaskpromptedtrainingenables}. Another possible way of creating a dataset of $(\texttt{instruction, output})$ pairs is to employ an existing LLM to generate such pairs. This approach has been explored for instance by \textcite{wang2023labelwordsanchorsinformation}.

    \begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{latex/images/rlhf.png}
    \caption{The 3-step pipeline of RLHF used by \textcite{ouyang2022traininglanguagemodelsfollow} to fine-tune an LLM. Note that Step 1 is analogous to SFT.}
    \label{fig:rlhf}
    \end{figure}

    \item \textbf{Reinforcement Learning from Human Feedback:} Reinforcement Learning from Human Feedback (RLHF), sometimes called Alignment and in some literature included in the SFT phase, is the final stage of training an LLM. RLHF is the process of aligning the output of the model to the preference of human users. Figure \ref{fig:rlhf} shows the progress of RLHF: the model is first fine-tuned in the SFT phase. Then, a reward model is trained on human-ranked responses and finally, using a policy optimization algorithm, such as PPO \cite{zhang2025instructiontuninglargelanguage}, the reward is maximized. This type of training allows the model to learn high-level objectives, such as values, tone, and behavior patterns. RLHF is also used to mitigate the possible harm the model could do once deployed in the real world \cite{ouyang2022traininglanguagemodelsfollow}. These unwanted responses include biased outputs, leaking private information, presenting misinformation as factual content, and generating harmful and toxic content \cite{weidinger2021ethicalsocialrisksharm}.
\end{enumerate}

\subsubsection{Decoding strategies} \label{sec:decoding}

During inference, given an input to the LLM, the input is first transformed into tokens, and then using these tokens, the model produces logits. The logits are converted into probabilities using a softmax function. Softmax is defined as

\begin{align}
    \sigma(z)_i = \frac{e^{z_i}}{\sum^{K}_{j=1}e^{z_j}}.
\end{align}

The softmax function normalizes the input vector into a probability distribution, fulfilling properties $\sigma(z)_i \in [0, 1]$ and $\sum_i^K \sigma(z)_i = 1$. Additionally, softmax has the property that for any $z_i, z_j$, where $z_i > z_j$, holds $\sigma(z)_i > \sigma(z)_j$. These properties make the softmax function especially functional for multi-class prediction, including token prediction.

Decoding is the process of selecting which token the model produces using the probabilities obtained. There are many different decoding strategies, which each affect the nature of the model's output. The most popular decoding strategies include \textit{greedy search}, \textit{top-$k$ sampling}, \textit{top-$p$ sampling}, and \textit{beam search} \cite{Minaee2024-fr}.

The greedy search is the simplest of the decoding methods. It is intuitive, straight-forward, and computationally inexpensive. The greedy search takes the most probable token at each step, discarding all others. Like other greedy algorithms, the greedy search does not achieve the global optimum by favoring local optima, often producing repetitive, generic output. One advantage of using the greedy search is that it is deterministic, meaning that the model will always produce the same output on the same input.

Unlike the greedy search that only considers the most probable token at any given step, beam search is a decoding method that considers multiple token sequences, "beams", at the same time. Beam search is a search tree algorithm that, given the starting token, finds the most likely sequence of tokens among $N$ beams, until the maximum sequence length $M$ is reached or the end-of-sequence token produced by the model. This means that at worst, the decoder has to keep track of $N^M$ sequences, making beam search much computationally intensive than greedy search. 

Top-$k$ sampling is a more sophisticated decoding method compared to greedy search. In top-$k$ sampling, $k$ is a constant hyperparameter that decides the number of candidates with the highest probabilities to be considered as the next output. The most intuitive way to describe top-$k$ sampling is to sort the logit probabilities into descending order, and pick the top $k$ candidates. The final candidate is selected from the top candidates following the relative probabilities. This approach ensures variety in the output, but prioritizes the most probable tokens \cite{holtzman2020curiouscaseneuraltext}.

Like top-$k$ sampling, top-$p$ sampling samples from a truncated distribution. The difference is the way of obtaining the distribution. In top-$p$ sampling, $p \in [0, 1]$ is a constant hyperparameter that decides the probability mass for the truncated distribution. One way of seeing the top-$p$ method is to once again sort the candidates in a descending order by their probabilities. Then, add candidates to the set of candidates until the total probability mass of the set of candidates exceeds $p$. The final token is obtained by sampling the truncated distribution \cite{holtzman2020curiouscaseneuraltext}. Using a probability mass instead of a constant number of candidates as the cut-off point for the truncated distribution means that the shape of the probability distribution affects the number of candidates: flat distributions have many candidates to sample from, while peaked distributions focus only on a few candidates.

One common approach used in sampling based decoding methods is to shape the distribution using a parameter called temperature \cite{ACKLEY1985147}. Including temperature $T$ as a hyperparameter, the softmax function becomes

\begin{align}
    \sigma(z)_i = \frac{e^{z_i/T}}{\sum^{K}_{j=1}e^{z_j/T}}.
\end{align}

The effect of $T$ on the distribution depends on its value: when $T \rightarrow \inf$, the distribution tends towards a uniform distribution, while when $T \rightarrow 0$ the distribution favors high probability outcomes even heavier \cite{xuan2025exploringimpacttemperaturescaling}.  

\subsection{In-Context Learning} \label{sec:icl}

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{latex/images/icl_example.png}
\caption{Illustration of the flow of in-context learning as per \textcite{dong-etal-2024-survey}}
\label{fig:icl}
\end{figure}

In-context learning is the practice of adapting a pre-trained LLM to a new task using only a few examples as a demonstration during inference \cite{NEURIPS2020_1457c0d6}. The idea is that, much like humans, the LLM can learn from analogy. Figure \ref{fig:icl} contains an example of ICL. Demonstration examples are usually formed by inserting data into a natural language template. Then, a query is concatenated to the demonstration set and given to the LLM as an input. By entering a demonstration set along with the query, the LLM is expected to learn the hidden pattern of the demonstration set, improving prediction accuracy \cite{dong-etal-2024-survey}. The input can also include an instruction that further describes the task that is to be completed by the LLM.

\textcite{dong-etal-2024-survey} define ICL formally as: given a query input text $x$ and a set of candidate responses $Y = \{y_1, \cdots, y_m\}$, the model $M$ predicts the candidate response with the highest score, conditioned on a demonstration set $C$. $C$ consists of $k$ demonstration examples, with an optional task instruction. The instruction can be the same across all examples or vary between examples, depending on whether the learning is \textit{cross-task} ICL or \textit{task-specific} ICL. Thus, $C = \{I, [(x_1^\prime, y_1^\prime), \cdots, (x_k^\prime, y_k^\prime)]\}$ for task-specific ICL and $C = \{(I_1, x_1^\prime, y_1^\prime), \cdots, (I_k, x_k^\prime, y_k^\prime)\}$ for cross-task ICL. The likelihood of a candidate response is calculated using a scoring function on the whole input:

\begin{align}
    P(y_j | x) := f_M(y_j, C, x).
\end{align}

The final prediction is the candidate with the highest score:

\begin{align}
    \hat{y} = \arg \max_{y_j \in Y}P(y_j|x).
\end{align}

ICL has a number of features that make it more attractive in comparison to fine-tuning a task-specific LM, but maybe the most prominent feature is that ICL is conducted on a pre-trained LLM during inference. This suggests that ICL is less resource intensive than fine-tuning, since no actual model parameter updates are made. In addition to savings in training resources, ICL has shown great promise in many reasoning-heavy tasks, even surpassing the capabilities of state-of-the-art fine-tuned language models in some tasks \cite{NEURIPS2020_1457c0d6}. However, studies have shown that ICL can be finicky and it's performance is sensitive to settings, including the form of the prompt template and the order and selection of demonstration examples \cite{wang2024largelanguagemodelslatent}. This poses a challenge for all applications of ICL in finding optimal performance, often requiring human intervention in adjusting the prompt and selecting the demonstrations.

\subsection{Hallucinations in LLMs} \label{sec:hallcinations}

Hallucinations in Natural Language Generation (NLG) tasks refer to generated content that does not faithfully follow the input or is nonsensical \cite{filippova-2020-controlled}. Traditionally, hallucinations in NLG have been categorized as \textit{intrinsic} and \textit{extrinsic} hallucinations \cite{maynez2020faithfulnessfactualityabstractivesummarization}. Intrinsic hallucinations refer to synthesized content present in the input, using terms or concepts available, but misrepresenting them, creating an unreliable output. Extrinsic hallucinations refer to generated output that ignores or discards the source material \cite{10.1145/3571730}.

In the context of LLMs, their versatility and usage in various fields of research and business have highlighted limitations in the existing categorization, creating the need for a more precise categorization of hallucinations. \textcite{10.1145/3703155}, based on the survey by \textcite{10.1145/3571730}, propose the categorization of LLM-generated hallucinations to \textit{factuality hallucinations} and \textit{faithfulness hallucinations}. This categorization is shown in \ref{fig:hallucination_types}, from which it can be seen that both categories have been further divided into multiple subcategories. The subcategories are explained in the following sections.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{latex/images/hallucination_types.png}
    \caption{Examples of each type of LLM hallucination presented by \textcite{10.1145/3703155}.}
    \label{fig:hallucination_types}
\end{figure}

\subsubsection{Factuality hallucinations} \label{sec:factuality_hallucinations}

Factuality hallucinations refer to generated content that deviates from established world knowledge, containing either inconsistentities that conflict real-world facts or unverifiable information. Factuality hallucinations are further divided into two subcategories:

\begin{enumerate}
    \item \textit{Factual contradiction} refers to situations where the LLM generates an output presenting information contradicting established knowledge as facts. Factual contradictions can be divided into two subcategories: \textit{entity-error hallucinations} and \textit{relation-error hallucinations}. This categorization is not universal and variations exist. \textcite{li2024dawndarkempiricalstudy} include in the categorization \textit{incompleteness hallucinations} and \textit{outdatedness hallucinations} in addition to previously mentioned hallucination types. Entity-error hallucinations contain erroneous entities in the output, shown in figure \ref{fig:hallucination_types} when Thomas Edison was falsely credited as the inventor of the telephone, although it in fact was developed by Alexander Graham Bell. Relation-error hallucinations, on the other hand, contain misrepresented relations between entities. From \ref{fig:hallucination_types}, the model claiming that Thomas Edison was the inventor of the lightbulb, when in reality he made improvements to the existing design, is a relation-error hallucination. Incompleteness hallucination refers to situations where the LLM output is clearly incomplete. This occurs most often when generating long or listed responses. An example of an incompleteness hallucination is the LLM producing a list of 7 popular fantasy books when asked to produce a list of 10. Outdatedness hallucinations occur when the knowledge of the LLM is out-of-date, and no longer true. For example, an LLM trained before 2025 would answer "Joe Biden", when asked about the current president of the United States, when the current answer is "Donald Trump".
    
    \item \textit{Factual fabrication} is a type of hallucination where the LLM output presents information that cannot be verified with current world knowledge as facts. Factual fabrications can be divided further into \textit{unverifiability hallucinations} and \textit{overclaim hallucinations}. Unverifiability hallucinations involve outputs that contain statements that are completely false or cannot be established with available knowledge. In figure \ref{fig:hallucination_types}, the claim "The construction of the Eiffel Tower in 1889 led to the extinction of the Parisian tiger" is an unverifiability hallucination, since the Parisian tiger does not exist, and thus the claim can not be verified against any records. Overclaim hallucinations, on the other hand, contain biased claims, making the output unreliable. An example of an overclaim hallucination can be found in figure \ref{fig:hallucination_types}: the claim that the construction of the Eiffel tower is  "widely recognized as the event that sparked the global green architecture movement", is an overclaim, since there is no evidence to the claim and no common understanding on the subject.

\end{enumerate}

\subsubsection{Faithfulness hallucinations} \label{sec:faithfulness_hallucinations}

Faithfulness hallucinations refer to generated content that does not follow the given context or set of instructions. They are divided into three subcategories:

\begin{enumerate}
    \item \textit{Instruction inconsistencies} are hallucinations in which the model's output does not follow the given instructions. Instruction inconsistensies may arise from the model's safety and operational guidelines, but in the perspective of hallucinations, the inconsistensy hallucinations refer to unintentional misalignment with non-malicious user input. Figure \ref{fig:hallucination_types}, shows an example of an instruction inconsistency hallucination, where the model is asked to perform a translation task, but the model performs a question-answering task instead.
    \item \textit{Context inconsistency} refers to model output that does not follow the user-provided context. In figure \ref{fig:hallucination_types}, the user-provided context states that the Nile originates in the Great Lakes region of central Africa, while the model states that the Nile originates in the mountain ranges of central Africa.
    \item \textit{Logical inconsistency} hallucinations can be detected most often in reasoning tasks. They show logical contradictions in the output. These inconsistencies can be found between inside reasoning steps and between steps and the final result of the reasoning task. The example in figure \ref{fig:hallucination_types} shows the logical inconsistency inside a reasoning step: Dividing both sides of $2x = 8$ by 2 incorrectly yields $x = 3$.
\end{enumerate}

\subsection{Causes of hallucinations} \label{sec:hallucination_causes}

The root-causes for hallucinations are multi-faceted, spanning the LLM ability obtaining process comprehensively. This section covers the three main elements from which hallucinations originate: data, training, and inference. 

\subsubsection{Hallucination from Data} \label{sec:data_hallucination}

Training LLMs require data in two forms: raw textual data used in the pre-training phase, which lays the foundation for the abilities and world knowledge of the model, and alignment data, in the form of $(\texttt{instruction, output})$ pairs, which trains the model to conform to and follow user instructions. While diverse data expands the abilities of LLMs, it is also one of the primary causes for LLM hallucinations \cite{Kalai2025-fl}. The hallucinations are caused by misinformation and biases in the pre-training data, as well as the knowledge boundaries of the pre-training data, and low-quality alignment data used in the SFT phase.

LLMs have been shown to have remarkable memorization capabilities \cite{carlini2023quantifyingmemorizationneurallanguage}. As the model size increases, the ability to memorize the pre-training data has been shown to improve \cite{JMLR:v24:22-1144}. The increasing demand for larger textual corpora for LLM pre-training results in the capability to maintain the data quality decreasing, meaning that more misinformation ends up in the pre-training datasets. This, combined with the findings of \textcite{carlini2023quantifyingmemorizationneurallanguage} that LLMs memorize repeated strings better, poses the risk of misinformation and biases making their way from the pre-training data to the model output.

Some hallucinations, mainly factual contradictions, are caused by the knowledge boundaries of the model. \textcite{Kalai2025-fl} state that when an LLM encounters a task outside of its domain of knowledge, it tends to guess, producing an overconfident and usually nonfactual answer. As stated before, the domain of knowledge of an LLM is established during the pre-training phase, so it follows that the knowledge boundaries also arise from the pre-training. Multiple aspects have an effect on the knowledge boundaries: the inability of the model to memorize everything in the pre-training data, the data containing outdated information and excluding current information  \cite{onoe-etal-2022-entity}, and the exclusion of legally restricted data, such as copyright protected knowledge \cite{min2024silolanguagemodelsisolating}.

Alignment data of low quality used in the SFT phase can also cause hallucinations. \textcite{gekhman2024doesfinetuningllmsnew} show that LLMs struggle to take in new information during SFT compared to pre-training. They also find, that the tendency of LLMs to hallucinate grows linearly with the amount of new information obtained during SFT.

\subsubsection{Hallucination from Training} \label{sec:training_hallucination}

As explained in more detail in section \ref{sec:training}, an LLM obtains it's capabilities through a 3-step training process, with general world-knowledge and language understanding being obtained in pre-training, task completion in SFT, and alignment with human preferences in RLHF. Although these phases are crucial for equipping LLMs with their exceptional language understanding capabilities, each phase has its pitfalls that may induce hallucinations.

The auto-regressive, unidirectional manner of predicting tokens conducted during pre-training limits the model's ability to capture sophisticated contextual dependencies leading to potential hallucinations. \textcite{li2023batgptbidirectionalautoregessivetalker} suggest that this could be alleviated by employing a bidirectional architecture. Additionally, the phenomenon of exposure bias, arising from optimizing with ground-truth labels during training but employing model predictions instead during inference, has been shown to cause hallucinations in a variety of neural language models \cite{wang-sennrich-2020-exposure}.

Referring to section \ref{sec:training}, SFT seeks to turn the capabilities of the LLM from a next token predictor into a language model that can follow instructions and complete tasks. It was established in section \ref{sec:data_hallucination} that alignment data outside the domain of knowledge of the model induce hallucinations. Furthermore, models are usually trained to complete each response, without the ability to express uncertainty \cite{Kalai2025-fl}. Not being able to respond 'I don't know' means the model has to guess and fabricate responses, manifesting as hallucinations \cite{yang2024alignmenthonesty, zhang2024rtuninginstructinglargelanguage}.

\textcite{azaria2023internalstatellmknows} propose that LLMs may have an internal mechanism to know the truthfulness of the responses generated. Despite that, LLMs consistently output unfactual responses. In addition, models have been shown to conform to and affirm users' beliefs over truthful ones. The root for this kind of behavior might be learned by the model during RLHF. While RLHF is used to teach the model to avoid generating harmful content and to follow values and behave in a specific way, studies \cite{sharma2025understandingsycophancylanguagemodels, wei2024simplesyntheticdatareduces} have shown that RLHF also encourages this sycophantic behavior in the model.

\subsubsection{Hallucination from Inference} \label{sec:inference_hallucination}

Decoding is a crucial component in utilizing the capabilities obtained by an LLM during training to the fullest. However, there are weaknesses in decoding strategies that can induce hallucinations. The greedy search is deterministic and always outputs the same response for the same input by selecting the most probable token at each step. The greedy search has many shortcomings, as they produce bland, low-quality text, and repeat false information if it is most probable. Through stochastic sampling,  LLMs can output diverse and rich content, circumventing the shortcomings of the greedy search. Although utilizing randomness in the selection process introduces a different reason for hallucinations, since sampling tokens includes the possibility selection of those with false or unfaithful content.

Although LLMs are equipped with breath-taking reasoning abilities, they may still fail completely on some tasks. Reasoning limits may be exceeded with complicated relations between objects in the prompt, even if the model possesses the knowledge needed for the task. Furthermore, \textcite{berglund2024reversalcursellmstrained} show a specific reasoning failure called the \textit{Reversal Curse}. The study shows that LLMs fail to generalize information and understand bidirectional relations. The Reversal Curse is exhibited when an LLM trained on a statement of the form "A is B" is asked to assess the truthfulness of the statement "B is A". For example, an LLM trained on "Homer Simpson is Bart Simpson's father." might fail to truthfully answer when asked "Who is Bart Simpson's father?", since the model cannot infer the relation from the training data.  

%Over-confidence?

%Softmax bottleneck?

\subsection{Hallucination Detection and Mitigation Methods}

The prevalence of hallucinations in LLMs has raised a lot of concern about their reliability and ability to perform in real-world tasks. For this reason, much research focuses on the detection and prevention of hallucinations. The methods of hallucination detection differ depending on the type of hallucination. Factuality hallucination detection aims to identify the unfactual content in the model's output, whereas faithfulness hallucination detection evaluates context together with the output, measuring the faithfulness of the output \cite{10.1145/3703155}. 

Factuality hallucination detection is generally done via fact-checking methods or model uncertainty estimation. Fact-checking is usually a two-step procedure: facts are extracted from the output and then verified against knowledge sources. A straight-forward method to evaluate the factuality of the output is through an external source, such as FACTSCORE \cite{min2023factscorefinegrainedatomicevaluation}. FACTSCORE extracts atomic facts from the generated content and computes the percentage of supported facts from trusted knowledge sources. Uncertainty estimation involves studying the internal state of the LLM. The token probability can be used as a metric for the model's certainty, where a low probability indicates strong uncertainty \cite{varshney2023stitchtimesavesnine}.

Many faithfulness hallucination detection methods employ a kind of metric to assess the faithfulness of the output. These metrics, such as \cite{nan-etal-2021-entity, durmus-etal-2020-feqa}, consider the overlap of the information in the context and output to determine the faithfulness of the output. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{latex/images/icl_faithfulness.png}
    \caption{Prompt design of evaluation of faithfulness of text summarization with ICL using GPT-3 by \textcite{Jain_2023}.}
    \label{fig:icl_faithfulness}
\end{figure}

A different kind of faithfulness hallucination detection method is to use an external LLM as a judging entity through in-context learning. \textcite{gao2023humanlikesummarizationevaluationchatgpt} found that by providing ChatGPT with strict evaluation guidelines, the original text as context and an LLM-generated summary, it was able to accurately assess the quality of the summary, including faithfulness. 

Figure \ref{fig:icl_faithfulness} shows the prompt design of the ICL evaluation framework used by \textcite{Jain_2023}. It features in-context demonstrations in blue and the task to evaluate the consistency of the provided summary based on the original text in red. In the actual experiment, 4 demonstration examples were used for each input, and the evaluated dimensions were consistency, relevance, fluency, and coherence. Unlike \textcite{gao2023humanlikesummarizationevaluationchatgpt}, \textcite{Jain_2023} did not provide the model with any evaluation guidelines, but the model's task was to predict the score only based on the in-context demonstrations. The study found that through ICL, the model was able to achieve state-of-the-art scores on summary relevance and consistency.

Various strategies are employed to mitigate hallucinations. Typical methods for hallucination mitigation are data filtering, model editing, and Retrieval-Augmented Generation (RAG). Data filtering seeks to decrease the frequency of LLM hallucinations arising from low quality pre-training data. By filtering out misinformation, biased information, and duplicate data among other unwanted data qualities from the pre-training data, the factual correctness of LLMs has been shown to improve \cite{gunasekar2023textbooksneed}. Additionally, diverse datasets consisting of multiple smaller high-quality datasets improve the generalization and cross-domain capabilities of LLMs \cite{gao2020pile800gbdatasetdiverse}, reducing hallucinations.

\begin{itemize}
    \item ICL! \cite{alazraki-etal-2025-need, madaan2023selfrefineiterativerefinementselffeedback, vamshi2026manifoldbasedsamplingincontexthallucination, Jain_2023}
\end{itemize}

\subsection{LLMs in CS Education}
\subsection{Automatic exercise generation?}

\clearpage

\section{Research material and methods}

This part is the core of your work, where you explain the methodological choices
you made, its limitations, how you pick your research material or subjects, the 
implementation of your study and the methods used. This section determines the 
methodological strengths and weaknesses of your thesis. Any earlier description 
of the method should limit itself to work done earlier by others. Here you tell 
your reader what you have done.

\begin{itemize}
        \item Feedback loop?
        \begin{itemize}
            \item Feed demonstration examples to model
            \item Prompt
            \item Output
            \item Decision: Factual output?
                \begin{itemize}
                    \item Yes -> Continue
                    \item No -> Add set [prompt, output, label, (reasoning)] to demonstration examples
                \end{itemize}
        \end{itemize}
\end{itemize}

\clearpage

\section{Results}

Present the results of your study here and answer the research questions, asked 
earlier in the thesis (in the introduction, perhaps), this study strives to 
answer. The scientific value of your work is measured by the results you obtain 
along with the arguments you give to back the answers to your research 
questions.

Be critical of the significance of your results. You may critically scrutinise 
the results and your interpretation of the results here, or you may do so later 
in the chapter with the discussion of your work or in the conclusions part.

This part should discuss how reliable the data used in the study are. You may 
discuss the reliability of the conclusions drawn from the study either in this 
chapter or later in the discussions part. You may have the discussion in a 
chapter of its own, separate from the summary or conclusions.


\clearpage

\section{Summary/Conclusions}
\label{sec:summary}

This is where you tie up any loose ends. Tell your reader briefly and clearly 
what you have done, what you have discovered, and the value of your discovery 
in the context of similar work done earlier. Draw clear conclusions regarding 
the research problem, sub-problems or hypotheses. You also discuss future lines 
of study and new questions your study might have posed.

As the author of the thesis, you alone are responsible for ensuring that the 
layout, form and structure of your thesis adheres to the guidelines outlined by 
your school. This template aims to help you meet these requirements.



\clearpage
%% Bibliography / list of references
%%

%%%%%% FOR THOSE WHO USE BIBLATEX %%%%%%
% Redefine 'visited on' to 'Accessed on' the 
%\DeclareFieldFormat{urldate}{%
%	(Accessed on %
%	\mkbibmonth{\thefield{urlmonth}}\addspace%
%	\thefield{urlday}\addcomma \addspace      %
%	\thefield{urlyear}\isdot)}

%\nocite{*} % print uncited references in the bibliography
\printbibliography[heading=bibintoc] %, add the title to the table of 
%                                                 contents title={References}.

%%%%%%%%%% END BIBLATEX STUFF %%%%%%%%%%

%% The hand-written bibliography
%\thesisbibliography % Required to get the bibliography title in toc and to get
                     % the page number hyperlink to the page correct.

%\begin{thebibliography}{99}
%
%  \bibitem{aaltolib} Citation Guide: Making a bibliography, \textit{Aalto 
%  	University Learning Centre}. Online article. Available  
%    \url{https://libguides.aalto.fi/c.php?g=410674&p=2797572}
%    (accessed on 14.7.2021)
%
%  \bibitem{Bringhurst} Bringhurst, R., \textit{Horizontal Motion. The Elements 
%  	of Typographic Style}, Point Roberts, WA: Hartley \& Marks, 1992. p. 26, 
%    pp.\ 25--36. Also available online as version 3.0 at  
%    %\url{https://smallpressblog.files.wordpress.com/2017/11/bringhurstelementsselections1.pdf} (accessed on 7 May 2021).
%
%  \bibitem{Dyson} Dyson, M. C., and Kipping, G. J., ``The Effects of Line Length 
%    and Method of Movement on Patterns of Reading from Screen,'' 
%    \textit{Visible Language,} vol.~2, no.~2, pp. 150--181, 1998.
%
%  \bibitem{Wikilinelength} Wikipedia contributors, ``Line length,'' 
%    \textit{Wikipedia: The Free Encyclopedia}, Wikimedia Foundation, Inc., 
%    22 July 2004.
%    \url{https://en.wikipedia.org/w/index.php?title=Line_length&oldid=997524503}
%    (accessed on 7 May 2021).
%
%\end{thebibliography}

%% Appendices
%% If you don't have appendices, your thesis ends here. Remove \clearpage,
%% \thesisappendix and the following text below. The last command of this file
%% is \end{document}.
\clearpage

\thesisappendix

\section{Contents of an appendix}
\label{app:contents}

Appendices are not essential in a thesis, and so you must plan the content of 
your thesis as if it does not contain an appendix. The appendix cannot be used 
as a dumping ground for text and ideas from an overgrown thesis.

An appendix is an independent entity, even though it complements the thesis. 
So, the appendix is not, say, just a list or image or table, but contains 
explanatory text as well that indicates the purpose of its content. It can 
contain code listings, like the one below for a simplified list of commands to 
create an appendix.

The appendix can contain figures that do not fit in to complement the text in 
the thesis. The numbering of figures is like that of equations: see figure~\ref{appfig:refraction}.

The numbering of tables is like that for equations and figures, as is evident 
from the caption of table~\ref{apptab:schedule}.

%% Example of a table in the appendix. Note how h places the table in the
%% current position.
\begin{table}[htb]
	\centering
	\caption{Caption for the table.}
	\label{apptab:schedule}
	\sffamily% change the font in the table to sans serif
	\fbox{
		\begin{tabular}{lp{0.5\linewidth}}
			9.00--9.55  & Safety instructions on the use of laboratories\\
			9.55--10.00 & Transfer to the laboratory
		\end{tabular}}
\end{table}

\end{document}
